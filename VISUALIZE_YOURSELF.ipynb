{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Fitbit_json_file_lists():\n",
    "    '''\n",
    "        takes in directory containing json files for heart rate\n",
    "        returns a list of paths to each individual file, as strings,\n",
    "        for easy consumption by next function\n",
    "    '''\n",
    "    path = str(pathlib.Path().absolute())\n",
    "    heart_jsons = []\n",
    "    calorie_jsons = []\n",
    "    location_csvs = []\n",
    "\n",
    "    for loc, dirs, files in os.walk('./json_heart_data'):\n",
    "        print('\\nvisiting location:', loc, '\\n')\n",
    "        # pass the current iteration's object pair (ignoring dirs)\n",
    "        # to our method dedicated to looking at a list of files \n",
    "        # in any arbitrary file location\n",
    "        print('FILES:', files, '\\n')\n",
    "        regexp = re.compile('(\\.json)$')\n",
    "        for f in files:\n",
    "            # rebuld the file name from the given directory name\n",
    "            # and the OS-specific file path separator we can get with os.sep\n",
    "            # and the filename we get from our iterator\n",
    "            fn = 'json_heart_data' + str(os.sep) + f\n",
    "            if os.path.isfile(fn):\n",
    "                match = re.search(regexp, fn)\n",
    "                if match:\n",
    "                    if match.group(0) == '.json':\n",
    "                        print('file name:', fn, ' size:', os.path.getsize(fn),'B ', end=' ')\n",
    "                        print('extension:', match.group(0))\n",
    "                        heart_jsons.append(path + '/' + fn)\n",
    "\n",
    "    for loc, dirs, files in os.walk('./json_calorie_data'):\n",
    "        print('\\nvisiting location:', loc, '\\n')\n",
    "        print('FILES:', files, '\\n')\n",
    "        regexp = re.compile('(\\.json)$')\n",
    "        for f in files:\n",
    "            fn = 'json_calorie_data' + str(os.sep) + f\n",
    "            if os.path.isfile(fn):\n",
    "                match = re.search(regexp, fn)\n",
    "                if match:\n",
    "                    if match.group(0) == '.json':\n",
    "                        print('file name:', fn, ' size:', os.path.getsize(fn),'B ', end=' ')\n",
    "                        print('extension:', match.group(0))\n",
    "                        calorie_jsons.append(path + '/' + fn)\n",
    "\n",
    "    for loc, dirs, files in os.walk('./csv_google_data'):\n",
    "        print('\\nvisiting location:', loc, '\\n')\n",
    "        print('FILES:', files, '\\n')\n",
    "        regexp = re.compile('(\\.csv)$')\n",
    "        for f in files:\n",
    "            fn = 'csv_google_data' + str(os.sep) + f\n",
    "            if os.path.isfile(fn):\n",
    "                match = re.search(regexp, fn)\n",
    "                if match:\n",
    "                    if match.group(0) == '.csv':\n",
    "                        print('file name:', fn, ' size:', os.path.getsize(fn),'B ', end=' ')\n",
    "                        print('extension:', match.group(0))\n",
    "                        location_csvs.append(path + '/' + fn)\n",
    "\n",
    "    return heart_jsons, calorie_jsons, location_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_heart_convert_csv(heart_json_path):\n",
    "    \n",
    "    heart = pd.read_json(heart_json_path)\n",
    "    # Empty lists for heartbeats/min and Fitbit 'Confidence' value\n",
    "    bpm_list = []\n",
    "    conf_list = []\n",
    "\n",
    "    # Populates empty lists with respective Fitbit values\n",
    "    for i in heart['value']:\n",
    "        bpm_list.append(i['bpm'])\n",
    "        conf_list.append(i['confidence'])\n",
    "\n",
    "    # Creates new pandas dataframes from populated lists\n",
    "    bpm_df = pd.DataFrame(bpm_list)\n",
    "    conf_df = pd.DataFrame(conf_list)\n",
    "\n",
    "    # Assigns dataframes as new series/columns in original dataframe\n",
    "    heart['BPM'] = bpm_df\n",
    "    heart['Confidence'] = conf_df\n",
    "    \n",
    "    # Exports dataframes as CSV\n",
    "    heart_csv = heart[['dateTime','BPM','Confidence']].to_csv('working_heart.csv')\n",
    "    return heart_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_calorie_convert_csv(calorie_json_path):\n",
    "\n",
    "    # Reads JSON file and renames column for Calories burned per minute\n",
    "    calor = pd.read_json(calorie_json_path)\n",
    "    calor.rename(columns={'value':'Calories'}, inplace=True)\n",
    "\n",
    "    # Exports dataframes as CSV\n",
    "    calorie_csv = calor.to_csv('working_calorie.csv')\n",
    "\n",
    "    return calorie_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Postgres_create_DB():\n",
    "    try:\n",
    "        # Creates connection to new DB, creates if nonexistant\n",
    "        conn = psycopg2.connect(\n",
    "            database='heartcaltrip',\n",
    "            user='steve_wortmann',\n",
    "            password='paigek#624',\n",
    "            host='localhost'\n",
    "        )\n",
    "\n",
    "        # Cursor set for SQL insertion\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Connected...\")\n",
    "\n",
    "        # DB tables to house both BPM 'Heart', Calories, and Geographic 'Trip' data are created\n",
    "        # Primary integer key is set for all tables\n",
    "        hearttable_sql='''\n",
    "                        CREATE SEQUENCE heart_timeID_seq\n",
    "                        START WITH 0\n",
    "                        INCREMENT BY 1\n",
    "                        MINVALUE 0\n",
    "                        NO MAXVALUE\n",
    "                        CACHE 1;\n",
    "        \n",
    "                        CREATE TABLE IF NOT EXISTS\n",
    "                            heart(\n",
    "                                time_id INTEGER PRIMARY KEY DEFAULT nextval('heart_timeID_seq'),\n",
    "                                dateTime TIMESTAMP,\n",
    "                                Bpm INTEGER,\n",
    "                                Confidence INTEGER\n",
    "                            );\n",
    "                    '''\n",
    "        cursor.execute(hearttable_sql)\n",
    "        conn.commit()\n",
    "        print(\"Created HEART Table...\")\n",
    "\n",
    "        calorietable_sql='''\n",
    "                        CREATE SEQUENCE calorie_timeID_seq\n",
    "                        START WITH 0\n",
    "                        INCREMENT BY 1\n",
    "                        MINVALUE 0\n",
    "                        NO MAXVALUE\n",
    "                        CACHE 1;\n",
    "        \n",
    "                        CREATE TABLE IF NOT EXISTS\n",
    "                            calorie(\n",
    "                                time_id INTEGER PRIMARY KEY DEFAULT nextval('calorie_timeID_seq'),\n",
    "                                dateTime TIMESTAMP,\n",
    "                                Calories FLOAT\n",
    "                            );\n",
    "                    '''\n",
    "        cursor.execute(calorietable_sql)\n",
    "        conn.commit()\n",
    "        print(\"Created CALORIE Table...\")\n",
    "\n",
    "        triptable_sql='''\n",
    "                        CREATE SEQUENCE trip_timeID_seq\n",
    "                        START WITH 0\n",
    "                        INCREMENT BY 1\n",
    "                        MINVALUE 0\n",
    "                        NO MAXVALUE\n",
    "                        CACHE 1;\n",
    "        \n",
    "                        CREATE TABLE IF NOT EXISTS\n",
    "                            trip(\n",
    "                                time_id INTEGER PRIMARY KEY DEFAULT nextval('trip_timeID_seq'),\n",
    "                                name TEXT,\n",
    "                                address TEXT,\n",
    "                                description TEXT,\n",
    "                                TimeSpan_begin TIMESTAMP,\n",
    "                                TimeSpan_end TIMESTAMP,\n",
    "                                calories DOUBLE PRECISION,\n",
    "                                avg_hr NUMERIC,\n",
    "                                avg_conf NUMERIC,\n",
    "                                longitude FLOAT,\n",
    "                                latitude FLOAT,\n",
    "                                LineString_coordinates TEXT\n",
    "                            );\n",
    "                    '''\n",
    "        cursor.execute(triptable_sql)\n",
    "        conn.commit()\n",
    "        print(\"Created TRIP Table...\")\n",
    "\n",
    "    except psycopg2.Error as error:\n",
    "            print(\"Modular Error...\")\n",
    "            print(error)\n",
    "\n",
    "    # Database resources are closed at the end of insertion cycles\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "            if conn:\n",
    "                conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility establishing database connection,cursor function returning all access objects\n",
    "def connect_PostgreSQL():\n",
    "    try:\n",
    "        dbconn = psycopg2.connect(\n",
    "            database='heartcaltrip',\n",
    "            user='steve_wortmann',\n",
    "            password='paigek#624',\n",
    "            host='localhost'\n",
    "        )\n",
    "        cursor = dbconn.cursor()\n",
    "        #print(\"Connected to 'heartcaltrip' database\")\n",
    "    except psycopg2.Error as error:\n",
    "        print(\"Error opening database\")\n",
    "        dbconn = handle_DB_error(dbconn, cursor)\n",
    "    return dbconn, cursor\n",
    "\n",
    "# Utility to close database resources to call after future insertions\n",
    "def close_DB_resources(dbconn, cursor):\n",
    "    try:\n",
    "        if dbconn:\n",
    "            dbconn.close()\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        #print(\"closed resources\")\n",
    "    except psycopg2.Error as err:\n",
    "        (\"Error closing resources\")\n",
    "\n",
    "# Utility to handle database errors\n",
    "def handle_DB_error(dbconn, cursor):\n",
    "    if dbconn:\n",
    "        try:\n",
    "            dbconn.rollback()\n",
    "            print(\"Rolled back transation\")\n",
    "        except psycopg2.Error as error:\n",
    "            print(\"Error rolling back transaction\")\n",
    "        finally:\n",
    "            close_DB_resources(dbconn, cursor)\n",
    "            dbconn = None \n",
    "            return dbconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pg_insert_heart_csv(heart_csv):\n",
    "    \n",
    "    heart_insert = '''INSERT INTO heart (time_id, dateTime, Bpm, Confidence)\n",
    "                      VALUES (DEFAULT,%s,%s,%s);\n",
    "                    '''\n",
    "\n",
    "    # BRM 'Heart' table is populated first from CSV...\n",
    "    dbconn, cursor = connect_PostgreSQL()\n",
    "\n",
    "    with open(heart_csv) as file:\n",
    "        time_stamps = csv.DictReader(file)\n",
    "        value_id = 0\n",
    "        for time in time_stamps:\n",
    "            value_id += 1\n",
    "            record = (time['dateTime'], time['BPM'], time['Confidence'])\n",
    "            cursor.execute(heart_insert, record)\n",
    "            dbconn.commit()\n",
    "        #print('All file records committed to database: BPM/HeartRate table...')\n",
    "\n",
    "    close_DB_resources(dbconn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pg_insert_calorie_csv(calorie_csv):\n",
    "    \n",
    "    calorie_insert = '''INSERT INTO calorie (time_id, dateTime, Calories)\n",
    "                        VALUES (DEFAULT,%s,%s);\n",
    "                    '''\n",
    "    # BRM 'Heart' table is populated first from CSV...\n",
    "    dbconn, cursor = connect_PostgreSQL()\n",
    "\n",
    "    with open(calorie_csv) as file:\n",
    "        time_stamps = csv.DictReader(file)\n",
    "        value_id = 0\n",
    "        for time in time_stamps:\n",
    "            value_id += 1\n",
    "            record = (time['dateTime'], time['Calories'])\n",
    "            cursor.execute(calorie_insert, record)\n",
    "            dbconn.commit()\n",
    "        #print('All file records committed to database: Caloric table...')\n",
    "\n",
    "    close_DB_resources(dbconn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pg_insert_location_csv(Google_location_csv):\n",
    "    \n",
    "    trip_insert = '''INSERT INTO trip (time_id, name, address, description, TimeSpan_begin, TimeSpan_end, longitude, latitude, LineString_coordinates)\n",
    "                     VALUES (DEFAULT,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "                    '''\n",
    "    \n",
    "    dbconn, cursor = connect_PostgreSQL()\n",
    "\n",
    "    with open(Google_location_csv) as file:\n",
    "        time_stamps = csv.DictReader(file)\n",
    "        value_id = 0\n",
    "        for time in time_stamps:\n",
    "            try:\n",
    "                float(time['longitude'])\n",
    "            except:\n",
    "                #print('invalid entry')\n",
    "                time['longitude'] = None\n",
    "                time['latitude'] = None\n",
    "\n",
    "            record = (time['\\ufeffname'], time['address'], time['description'], time['TimeSpan_begin'], time['TimeSpan_end'], time['longitude'], time['latitude'], time['LineString_coordinates'])\n",
    "            cursor.execute(trip_insert, record)\n",
    "            dbconn.commit()\n",
    "        #print('All file records committed to database: Geographic/Location table...')\n",
    "\n",
    "    close_DB_resources(dbconn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Postgres_combine_view():\n",
    "    # Readings within 'dateTime' are truncated down to their minute value\n",
    "    # Average values for BPM and Confidence readings are taken per minute period\n",
    "    # Summation of Calorie values are taken over for every minute period\n",
    "    # All values are singularly grouped for every minute, then ordered chronologically...\n",
    "\n",
    "    # These values are populated as single postgres View resource...\n",
    "    create_calorie_heartrate_view = '''CREATE VIEW calorie_heartrate AS\n",
    "                     SELECT date_trunc('minute', h.dateTime) AS dateTime_min,\n",
    "                     avg(h.Bpm) AS BPM_min_avg, avg(h.Confidence) AS Conf_min_avg,\n",
    "                     avg(c.calories) AS calories\n",
    "                     FROM heart AS h\n",
    "                     JOIN calorie as c\n",
    "                     ON c.dateTime = date_trunc('minute', h.dateTime)\n",
    "                     GROUP BY date_trunc('minute', h.dateTime)\n",
    "                     ORDER BY date_trunc('minute', h.dateTime);\n",
    "                  ''' \n",
    "\n",
    "    # All newly-generated minute values for Calories, BPM, Confidence are collected from View...\n",
    "    pull_calorie_heartrate = '''SELECT dateTime_min, calories, BPM_min_avg, Conf_min_avg FROM calorie_heartrate;''' \n",
    "\n",
    "    # First insertion is executed, compended postgres View is created of most-relevant data\n",
    "    # View is then fetched, that data is then stored in a single tuple...\n",
    "\n",
    "    dbconn, cursor = connect_PostgreSQL()\n",
    "\n",
    "    cursor.execute(create_calorie_heartrate_view)\n",
    "    dbconn.commit()\n",
    "    print('Grouping data readings per minute...')\n",
    "    cursor.execute(pull_calorie_heartrate)\n",
    "    tupples = cursor.fetchall()\n",
    "    print('Extracting data approximations from Postgres...')\n",
    "\n",
    "    close_DB_resources(dbconn, cursor)\n",
    "    \n",
    "    # That tuple is used to create new pd Dataframe of Calories + Average HeartRate per minute...\n",
    "    calorie_heartrate_df = pd.DataFrame(tupples, columns=['dateTime','calories','bpm_min','conf_min'])\n",
    "    return calorie_heartrate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Postgres_populate_Trip_table():\n",
    "    \n",
    "    dbconn, cursor = connect_PostgreSQL()\n",
    "\n",
    "    trip_pull = '''SELECT * FROM trip\n",
    "                   ORDER BY time_id;'''\n",
    "\n",
    "    heart_cal_pull = '''SELECT sum(c_hr.calories) AS calories,\n",
    "                               avg(c_hr.bpm_min_avg) AS avg_bpm,\n",
    "                               avg(c_hr.conf_min_avg) AS confidence\n",
    "                        FROM calorie_heartrate AS c_hr\n",
    "                        WHERE c_hr.dateTime_min\n",
    "                        BETWEEN (%s) AND (%s);\n",
    "                     '''\n",
    "\n",
    "    trip_fill_columns =  '''UPDATE public.trip\n",
    "                            SET calories = CAST(%s AS DOUBLE PRECISION),\n",
    "                                avg_hr = (%s),\n",
    "                                avg_conf = (%s)\n",
    "                            WHERE\n",
    "                                time_id = (%s);\n",
    "                         '''\n",
    "\n",
    "    insertion_record = '''SELECT calories, avg_hr, avg_conf FROM trip\n",
    "                          WHERE time_id = (%s);\n",
    "                          '''\n",
    "\n",
    "    final_trip_pull = '''SELECT time_id, name, address, timespan_begin, timespan_end,\n",
    "                         calories, avg_hr, avg_conf, longitude, latitude, linestring_coordinates, description\n",
    "                         FROM trip ORDER BY time_id;\n",
    "                         '''\n",
    "\n",
    "    # Location 'Trip' table is scanned, iterated by its consecutive time periods at a location (or in transit)\n",
    "\n",
    "    # For each arbitrary time period expressed:\n",
    "    #    - Our Postgres View of minutely-segregated calories burned, and average BPM readings, are collected.\n",
    "    #        - Each per-minute reading is then again either summated or averaged to a single value.\n",
    "    #        - These values are used for insertion into their respective column on 'Trip' table, via 'heart_cal_period'.\n",
    "    #        - 'heart_cal_period' matches values within their appropriate time period.\n",
    "\n",
    "    cursor.execute(trip_pull)\n",
    "    trip_record = cursor.fetchall()\n",
    "\n",
    "    for row in trip_record:\n",
    "        cursor.execute(heart_cal_pull, (row[4], row[5]))\n",
    "        heart_cal_period = cursor.fetchone()\n",
    "        if heart_cal_period:\n",
    "            cursor.execute(trip_fill_columns, (heart_cal_period[0], heart_cal_period[1], heart_cal_period[2], row[0]))\n",
    "            cursor.execute(insertion_record, (row[0],))\n",
    "            #print(cursor.fetchone())\n",
    "\n",
    "    print(\"\\nColumns populated: 'calories', 'average_hr', 'avg_conf'\")\n",
    "    print(\"Total rows are: \", len(trip_record))\n",
    "\n",
    "    dbconn.commit()\n",
    "\n",
    "    cursor.execute(final_trip_pull)\n",
    "    trip_tupple = cursor.fetchall()\n",
    "\n",
    "    close_DB_resources(dbconn, cursor)\n",
    "    \n",
    "    total_trip_df = pd.DataFrame(trip_tupple, columns=['time_id','Name','Address','Time begin','Time end','Calories','BPM avg','BPM conf','Longitude','Latitude','LineString_coord','Description'])\n",
    "    total_trip_df.to_csv('finished_table.csv')\n",
    "    # pandas dataframe for calories and heartrate also generated, if needed...\n",
    "    return total_trip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    Postgres_create_DB()\n",
    "    heart_jsons, calorie_jsons, location_csvs = generate_Fitbit_json_file_lists()\n",
    "    \n",
    "    file_id = 0\n",
    "    \n",
    "    for file in heart_jsons:\n",
    "        heart_result_csv = json_heart_convert_csv(file)\n",
    "        Pg_insert_heart_csv('working_heart.csv')\n",
    "        file_id += 1\n",
    "        print('Heart file', file_id, 'committed...')\n",
    "    print('Heart rate data committed to database.\\n')\n",
    "    file_id = 0\n",
    "    \n",
    "    for file in calorie_jsons:\n",
    "        calorie_result_csv = json_calorie_convert_csv(file)\n",
    "        Pg_insert_calorie_csv('working_calorie.csv')\n",
    "        file_id += 1\n",
    "        print('Caloric file', file_id, 'committed...')\n",
    "    print('Caloric data committed to database.\\n')\n",
    "    file_id = 0\n",
    "    \n",
    "    for file in location_csvs:\n",
    "        Pg_insert_location_csv(file)\n",
    "        file_id += 1\n",
    "        print('Location file', file_id, 'committed...')\n",
    "    print('Location data committed to database.\\n')\n",
    "    \n",
    "    Postgres_combine_view()\n",
    "    Postgres_populate_Trip_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected...\n",
      "Created HEART Table...\n",
      "Created CALORIE Table...\n",
      "Created TRIP Table...\n",
      "\n",
      "visiting location: ./json_heart_data \n",
      "\n",
      "FILES: ['heart_rate-2020-10-06.json', 'heart_rate-2020-10-10.json', 'heart_rate-2020-10-11.json', '.DS_Store', 'heart_rate-2020-10-07.json', 'heart_rate-2020-10-02.json', 'heart_rate-2020-10-03.json', 'heart_rate-2020-10-08.json', 'heart_rate-2020-10-04.json', 'heart_rate-2020-10-05.json', 'heart_rate-2020-10-09.json'] \n",
      "\n",
      "file name: json_heart_data/heart_rate-2020-10-06.json  size: 1106052 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-10.json  size: 1136809 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-11.json  size: 1056491 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-07.json  size: 1097375 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-02.json  size: 1055092 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-03.json  size: 996233 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-08.json  size: 1063639 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-04.json  size: 1112547 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-05.json  size: 1111915 B  extension: .json\n",
      "file name: json_heart_data/heart_rate-2020-10-09.json  size: 1152332 B  extension: .json\n",
      "\n",
      "visiting location: ./json_calorie_data \n",
      "\n",
      "FILES: ['calories-2020-09-14.json', '.DS_Store'] \n",
      "\n",
      "file name: json_calorie_data/calories-2020-09-14.json  size: 2543088 B  extension: .json\n",
      "\n",
      "visiting location: ./csv_google_data \n",
      "\n",
      "FILES: ['denver_trip.csv'] \n",
      "\n",
      "file name: csv_google_data/denver_trip.csv  size: 231009 B  extension: .csv\n",
      "Heart file 1 committed...\n",
      "Heart file 2 committed...\n",
      "Heart file 3 committed...\n",
      "Heart file 4 committed...\n",
      "Heart file 5 committed...\n",
      "Heart file 6 committed...\n",
      "Heart file 7 committed...\n",
      "Heart file 8 committed...\n",
      "Heart file 9 committed...\n",
      "Heart file 10 committed...\n",
      "Heart rate data committed to database.\n",
      "\n",
      "Caloric file 1 committed...\n",
      "Caloric data committed to database.\n",
      "\n",
      "Location file 1 committed...\n",
      "Location data committed to database.\n",
      "\n",
      "Grouping data readings per minute...\n",
      "Extracting data approximations from Postgres...\n",
      "\n",
      "Columns populated: 'calories', 'average_hr', 'avg_conf'\n",
      "Total rows are:  125\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
